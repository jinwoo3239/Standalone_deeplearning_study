{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
    "\n",
    "train_val_dataset = datasets.CIFAR10('./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_size = int(len(train_val_dataset) * 0.8)\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, lengths=[train_size, val_size])\n",
    "\n",
    "dataset_partition = {'train' : train_dataset, 'val' : val_dataset, 'test' : test_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=3072, out_features=32, bias=True)\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (bn_layers): ModuleList(\n",
       "    (0-1): 2 x BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
       "  (act): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, act_fn, dropout_prob, n_layer, use_bn, use_weight_init):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.bn_layers = nn.ModuleList()\n",
    "\n",
    "        self.n_layer = n_layer\n",
    "        self.use_bn = use_bn\n",
    "        for i in range(self.n_layer-1):\n",
    "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "\n",
    "            if self.use_bn:\n",
    "                self.bn_layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "        self.act_fn = act_fn\n",
    "\n",
    "        if self.act_fn == 'relu':\n",
    "            self.act = nn.ReLU()\n",
    "        elif self.act_fn == 'tanh':\n",
    "            self.act = nn.Tanh()\n",
    "        elif self.act_fn == 'sigmoid':\n",
    "            self.act = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError('Valid activation function should be selected. List of activation function is [relu, tanh, sigmoid]')\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "        if use_weight_init:\n",
    "            self._weight_init()\n",
    "\n",
    "\n",
    "    def _weight_init(self,):\n",
    "\n",
    "        if self.act_fn == 'relu':\n",
    "            nn.init.kaiming_normal_(self.fc1.weight)\n",
    "            nn.init.kaiming_normal_(self.fc2.weight)\n",
    "            for linear in self.layers:\n",
    "                if isinstance(linear, nn.Linear):\n",
    "                    nn.init.kaiming_normal_(linear.weight)\n",
    "        \n",
    "        elif self.act_fn == ('tanh' or 'sigmoid'):\n",
    "            nn.init.xavier_normal_(self.fc1.weight)\n",
    "            nn.init.xavier_normal_(self.fc2.weight)\n",
    "            for linear in self.layers:\n",
    "                if isinstance(linear, nn.Linear):\n",
    "                    nn.init.xavier_normal_(linear.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.fc1(x)\n",
    "        for i in range(self.n_layer-1):\n",
    "            x = self.layers[i](x)\n",
    "            if self.use_bn:\n",
    "                x = self.bn_layers[i](x)\n",
    "\n",
    "            x = self.act(x)\n",
    "            self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "model = MLP(3072, 32, 10, 'relu', 0.5, 3, True, True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.batch_size\n",
    "\n",
    "def train(model, dataset_partition, optimizer, loss_fn, args, device):\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    train_dataloader = DataLoader(dataset_partition['train'], batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    train_losses = 0.0\n",
    "    train_correct = 0.0\n",
    "\n",
    "    for img, label in train_dataloader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(img)\n",
    "        loss = loss_fn(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses += loss.cpu().detach().numpy()\n",
    "\n",
    "        prediction = torch.argmax(outputs, dim=-1)\n",
    "        correct = torch.eq(prediction, label).sum()\n",
    "        train_correct += correct.cpu().detach().numpy()\n",
    "    \n",
    "    train_losses /= len(train_dataloader)\n",
    "    train_correct /= len(train_dataloader.dataset)\n",
    "    return model, train_losses, train_correct\n",
    "\n",
    "\n",
    "def validation(model, dataset_partition, loss_fn, args, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    valid_dataloader = DataLoader(dataset_partition['val'], batch_size=args.batch_size)\n",
    "\n",
    "    valid_losses = 0.0\n",
    "    valid_correct = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in valid_dataloader:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            outputs = model(img)\n",
    "            loss = loss_fn(outputs, label)\n",
    "\n",
    "            valid_losses += loss.cpu().detach().numpy()\n",
    "            prediction = torch.argmax(outputs, dim=-1)\n",
    "            valid_correct += torch.eq(prediction, label).sum().cpu().detach().numpy()\n",
    "        valid_losses /= len(valid_dataloader)\n",
    "        valid_correct /= len(valid_dataloader.dataset)\n",
    "    \n",
    "    return model, valid_losses, valid_correct\n",
    "\n",
    "\n",
    "def test(model, dataset_partition, args, device):\n",
    "    model = model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    test_dataloader = DataLoader(dataset_partition['test'], batch_size=args.batch_size)\n",
    "\n",
    "    test_correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        for img, label in test_dataloader:\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            outputs = model(img)\n",
    "            prediction = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "            correct = torch.eq(prediction, label).sum().cpu().detach().numpy()\n",
    "            test_correct += correct\n",
    "\n",
    "    \n",
    "        test_correct /= len(test_dataloader.dataset)\n",
    "    return model, test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(dataset_partition, args, device):\n",
    "    model = MLP(args.in_dim, args.hidden_dim, args.out_dim, args.act, args.dropout_prob, args.n_layer, args.use_bn, args.use_weight_init)\n",
    "    model = model.to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args.learning_rate)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    else:\n",
    "        raise ValueError('Valid optmizer should be seleceted')\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        ts = time.time()\n",
    "        model, train_loss, train_acc = train(model, dataset_partition, optimizer, loss_fn, args, device)\n",
    "        model, valid_loss, valid_acc = validation(model, dataset_partition, loss_fn, args, device)\n",
    "        te = time.time()\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accs.append(valid_acc)\n",
    "\n",
    "        print(f'Epoch {epoch}, ACCURACY(train/valid) : {train_acc * 100:.2f}/{valid_acc * 100 :.2f}. LOSS(train/valid : {train_loss:.2f}/{valid_loss:.2f}. TOOK sec : {te-ts:.2f}')\n",
    "    \n",
    "    model, test_acc = test(model, dataset_partition, args, device)\n",
    "\n",
    "    result = {}\n",
    "    result['train_losses'] = train_losses\n",
    "    result['valid_losses'] = valid_losses\n",
    "    result['train_acc'] = train_accs\n",
    "    result['valid_acc'] = valid_accs\n",
    "    result['test_acc'] = test_acc\n",
    "    return vars(args), result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_exp_result(setting:dict, result:dict):\n",
    "    exp_name = setting['exp_name']\n",
    "\n",
    "    result.update(setting)\n",
    "    random_key = int(random.random()*1e7)\n",
    "    if not os.path.exists('./results'):\n",
    "        os.mkdir('./results')\n",
    "\n",
    "    filename = f'./results/{exp_name}_{random_key}.json'\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(result, f)\n",
    "\n",
    "def load_exp_result(exp_name):\n",
    "    dir_path = './results'\n",
    "    file_names = [f for f in os.listdir(dir_path) if '.json' in f]\n",
    "\n",
    "    list_results = []\n",
    "\n",
    "    for file in file_names:\n",
    "        if exp_name in file:\n",
    "            with open(os.path.join(dir_path, file), 'r') as f:\n",
    "                result = json.load(f)\n",
    "                list_results.append(result)\n",
    "    df = pd.DataFrame(list_results)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(exp_name='exp1_bn_weight_init', in_dim=3072, out_dim=10, hidden_dim=256, act='relu', n_layer=1, dropout_prob=0.2, use_bn=True, use_weight_init=True, optim='Adam', epoch=5, batch_size=256, learning_rate=0.001)\n",
      "Epoch 0, ACCURACY(train/valid) : 32.86/36.47. LOSS(train/valid : 2.09/1.87. TOOK sec : 3.43\n",
      "Epoch 1, ACCURACY(train/valid) : 37.45/35.61. LOSS(train/valid : 1.83/1.90. TOOK sec : 3.21\n",
      "Epoch 2, ACCURACY(train/valid) : 39.11/38.26. LOSS(train/valid : 1.77/1.80. TOOK sec : 3.29\n",
      "Epoch 3, ACCURACY(train/valid) : 40.61/39.34. LOSS(train/valid : 1.72/1.76. TOOK sec : 3.37\n",
      "Epoch 4, ACCURACY(train/valid) : 41.39/40.23. LOSS(train/valid : 1.71/1.76. TOOK sec : 3.35\n",
      "Namespace(exp_name='exp1_bn_weight_init', in_dim=3072, out_dim=10, hidden_dim=256, act='relu', n_layer=1, dropout_prob=0.2, use_bn=True, use_weight_init=False, optim='Adam', epoch=5, batch_size=256, learning_rate=0.001)\n",
      "Epoch 0, ACCURACY(train/valid) : 35.58/38.46. LOSS(train/valid : 1.86/1.77. TOOK sec : 3.32\n",
      "Epoch 1, ACCURACY(train/valid) : 39.09/39.33. LOSS(train/valid : 1.76/1.76. TOOK sec : 3.31\n",
      "Epoch 2, ACCURACY(train/valid) : 40.16/39.01. LOSS(train/valid : 1.73/1.75. TOOK sec : 3.27\n",
      "Epoch 3, ACCURACY(train/valid) : 40.85/40.53. LOSS(train/valid : 1.72/1.74. TOOK sec : 3.26\n",
      "Epoch 4, ACCURACY(train/valid) : 41.06/40.08. LOSS(train/valid : 1.71/1.74. TOOK sec : 3.26\n",
      "Namespace(exp_name='exp1_bn_weight_init', in_dim=3072, out_dim=10, hidden_dim=256, act='relu', n_layer=1, dropout_prob=0.2, use_bn=False, use_weight_init=True, optim='Adam', epoch=5, batch_size=256, learning_rate=0.001)\n",
      "Epoch 0, ACCURACY(train/valid) : 32.37/33.96. LOSS(train/valid : 2.10/1.94. TOOK sec : 3.26\n",
      "Epoch 1, ACCURACY(train/valid) : 37.22/36.12. LOSS(train/valid : 1.83/1.87. TOOK sec : 3.26\n",
      "Epoch 2, ACCURACY(train/valid) : 38.94/39.61. LOSS(train/valid : 1.77/1.77. TOOK sec : 3.26\n",
      "Epoch 3, ACCURACY(train/valid) : 40.81/38.49. LOSS(train/valid : 1.72/1.77. TOOK sec : 3.26\n",
      "Epoch 4, ACCURACY(train/valid) : 41.12/40.55. LOSS(train/valid : 1.70/1.74. TOOK sec : 3.26\n",
      "Namespace(exp_name='exp1_bn_weight_init', in_dim=3072, out_dim=10, hidden_dim=256, act='relu', n_layer=1, dropout_prob=0.2, use_bn=False, use_weight_init=False, optim='Adam', epoch=5, batch_size=256, learning_rate=0.001)\n",
      "Epoch 0, ACCURACY(train/valid) : 35.51/38.26. LOSS(train/valid : 1.87/1.78. TOOK sec : 3.27\n",
      "Epoch 1, ACCURACY(train/valid) : 39.44/40.12. LOSS(train/valid : 1.75/1.76. TOOK sec : 3.26\n",
      "Epoch 2, ACCURACY(train/valid) : 40.25/40.12. LOSS(train/valid : 1.73/1.74. TOOK sec : 3.26\n",
      "Epoch 3, ACCURACY(train/valid) : 40.76/39.23. LOSS(train/valid : 1.72/1.78. TOOK sec : 3.26\n",
      "Epoch 4, ACCURACY(train/valid) : 41.04/41.13. LOSS(train/valid : 1.71/1.73. TOOK sec : 3.25\n"
     ]
    }
   ],
   "source": [
    "# Random Seed initialization\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cpu')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Experiment_name\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.exp_name = 'exp1_bn_weight_init'\n",
    "\n",
    "# Model capacity\n",
    "args.in_dim = 3072\n",
    "args.out_dim = 10\n",
    "args.hidden_dim = 256\n",
    "args.act = 'relu'\n",
    "\n",
    "args.n_layer = 1\n",
    "\n",
    "# Regularization\n",
    "args.dropout_prob = 0.2\n",
    "args.use_bn = True\n",
    "args.use_weight_init = True\n",
    "\n",
    "# Optimization & Training\n",
    "args.optim = 'Adam'\n",
    "args.epoch = 5\n",
    "args.batch_size = 256\n",
    "args.learning_rate = 1e-3\n",
    "\n",
    "# Experiment values\n",
    "exp1_var1 = 'use_bn'\n",
    "exp1_var1_values = [True, False]\n",
    "\n",
    "exp1_var2 = 'use_weight_init'\n",
    "exp1_var2_values = [True, False]\n",
    "\n",
    "for var1 in exp1_var1_values:\n",
    "    for var2 in exp1_var2_values:\n",
    "        setattr(args, exp1_var1, var1)\n",
    "        setattr(args, exp1_var2, var2)\n",
    "        print(args)\n",
    "\n",
    "        setting, results = experiment(dataset_partition, args, device)\n",
    "        save_exp_result(setting, results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "exp1_var1 = 'use_bn'\n",
    "exp1_var2 = 'use_weight_init'\n",
    "\n",
    "df_exp = load_exp_result('exp1')\n",
    "df_exp['train_acc_final'] = df_exp.train_acc.apply(lambda x: x[-1])\n",
    "df_exp['valid_acc_final'] = df_exp.valid_acc.apply(lambda x: x[-1])\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2))\n",
    "sns.barplot(x='use_bn', y='train_acc_final', data=df_exp, hue='use_weight_init')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16c70bb53c3ff8e5cfee2d1d0545620c7a8a776b7a10915918312ca7b660aca5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
